{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "DAP_LAB5_1689_17993.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it4YEjDpB6jk"
      },
      "source": [
        "Univerzitet u Sarajevu\n",
        "\n",
        "Elektrotehnički fakultet\n",
        "\n",
        "#### **Dubinska analiza podataka**\n",
        "\n",
        "# Laboratorijska vježba 5. - Sintetičko stvaranje podataka\n",
        "\n",
        "---"
      ],
      "id": "it4YEjDpB6jk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSGIhpI0B6j2"
      },
      "source": [
        "Izrada laboratorijske vježbe vrši se u ovom *Jupyter Notebook*-u. Isti je potrebno konvertovati u PDF dokument i predati na email adresu ekrupalija1@etf.unsa.ba."
      ],
      "id": "hSGIhpI0B6j2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSseODfKB6j2"
      },
      "source": [
        "Ime i prezime studenta, broj indeksa:"
      ],
      "id": "gSseODfKB6j2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48ytoUCgB6j3"
      },
      "source": [
        "Haris Masovic, 1689/17993"
      ],
      "id": "48ytoUCgB6j3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL9M8faZB6j3"
      },
      "source": [
        "Datum izrade izvještaja:"
      ],
      "id": "UL9M8faZB6j3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YbQMYq3B6j3"
      },
      "source": [
        "11.04.2021"
      ],
      "id": "1YbQMYq3B6j3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKPrKPLvB6j3"
      },
      "source": [
        "## Dependencies"
      ],
      "id": "WKPrKPLvB6j3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RccDA-_B6j4",
        "outputId": "a340bbeb-a6b8-4627-e092-24b12ebbb10d"
      },
      "source": [
        "import sys\n",
        "!pip install nlpaug snorkel transformers"
      ],
      "id": "2RccDA-_B6j4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nlpaug\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/f8/b11caecdd19aa2b1b2cb46c6cbbec692abd621aad884e653e459a8546add/nlpaug-1.1.3-py3-none-any.whl (394kB)\n",
            "\u001b[K     |████████████████████████████████| 399kB 10.3MB/s \n",
            "\u001b[?25hCollecting snorkel\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/e4/74674d73574db5d2d9fe74440c33ba873afe93f36e8e54762e36b090ed39/snorkel-0.9.7-py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 22.9MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 12.0MB/s \n",
            "\u001b[?25hCollecting munkres>=1.0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/90/ab/0301c945a704218bc9435f0e3c88884f6b19ef234d8899fb47ce1ccfd0c9/munkres-1.1.4-py2.py3-none-any.whl\n",
            "Collecting networkx<2.4,>=2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 57.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.8.1+cu101)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.4.1)\n",
            "Requirement already satisfied: numpy<1.20.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.19.5)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (4.41.1)\n",
            "Collecting tensorboard<2.0.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 53.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<0.25.0,>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (0.22.2.post1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 41.8MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx<2.4,>=2.2->snorkel) (4.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.2.0->snorkel) (3.7.4.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->snorkel) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->snorkel) (2.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (3.3.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (1.32.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (54.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.20.2->snorkel) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: networkx, sacremoses\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556408 sha256=22372f85711fd45c3d964f04685b8918a4762fb62b6535507fbbf2ce485959fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=176fe606f65b7d9be252906ad4a788b2deddee0f379c49fbaf6f21c0caaac20b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built networkx sacremoses\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: nlpaug, munkres, networkx, tensorboard, snorkel, sacremoses, tokenizers, transformers\n",
            "  Found existing installation: networkx 2.5\n",
            "    Uninstalling networkx-2.5:\n",
            "      Successfully uninstalled networkx-2.5\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "Successfully installed munkres-1.1.4 networkx-2.3 nlpaug-1.1.3 sacremoses-0.0.44 snorkel-0.9.7 tensorboard-1.15.0 tokenizers-0.10.2 transformers-4.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78TQyfL9B6j5"
      },
      "source": [
        "## Zadatak 1. - Zamjena stringa na nivou slova\n",
        "\n",
        "Za sintetičku (vještačku) promjenu tekstualnih podataka koristeći tehnike prirodne obrade teksta (NLP) koristi se biblioteka <code> nlpaug </code> koju je potrebno instalirati preko konzole (<code> pip install nlpaug </code>). Osnovne informacije o ovoj biblioteci mogu se naći na [sljedećem linku](https://github.com/makcedward/nlpaug) i [sljedećem linku](https://nlpaug.readthedocs.io/en/latest/augmenter/augmenter.html).\n",
        "\n",
        "Prvo je potrebno izvršiti import neophodnih biblioteka, što je izvršeno u nastavku."
      ],
      "id": "78TQyfL9B6j5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1R9IQPBB6j5"
      },
      "source": [
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as nafc\n",
        "from nlpaug.util import Action\n",
        "\n",
        "# isključivanje prikaza upozorenja za deprecated funkcije\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "P1R9IQPBB6j5",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4amoFAWB6j6"
      },
      "source": [
        "Zamjena na nivou slova vrši se koristeći različite objekte iz biblioteke <code> nlpaug.augmenter.char </code>. U nastavku će se koristiti sljedeći objekti:\n",
        "\n",
        "1. <code> nac.OcrAug() </code>, koji dodaje OCR grešku u postojeći string;\n",
        "\n",
        "2. <code> nac.KeyboardAug() </code>, koji mijenja slova slovima koja imaju blizak ASCII broj;\n",
        "\n",
        "3. <code> nac.RandomCharAug(action = x) </code>, koji vrši specificiranu akciju bez zakonitosti, odnosno nad nasumičnim karakterima stringa. <code> x </code> je potrebno zamijeniti akcijom koja se želi izvršiti (<code> 'insert' </code>, <code> 'substitute' </code>, <code> 'swap' </code> ili <code> 'delete' </code>).\n",
        "\n",
        "Nad kreiranim objektom za zamjenu slova može se primijeniti funkcija <code> augment </code> koja kao parametar prima string nad kojim se vrši zamjena na nivou slova. Kao rezultat se dobiva modificirani string."
      ],
      "id": "W4amoFAWB6j6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs_Cl0vDB6j6"
      },
      "source": [
        "**Zadatak:**\n",
        "    \n",
        "> Definisati string 'Dubinska analiza podataka', a zatim nad njim izvršiti zamjenu na nivou slova koristeći sve prethodno opisane objekte (OCR, ASCII i četiri nasumična augmentatora). Prikazati originalni i sve modificirane stringove.\n",
        ">\n",
        ">> **Uputstvo:**\n",
        ">>\n",
        ">> Sve rezultujuće stringove smjestiti u zasebne varijable, jer će ih biti neophodno koristiti u sljedećem dijelu zadatka. Paziti da se ne pobriše vrijednost originalnog stringa (iz istog razloga)."
      ],
      "id": "hs_Cl0vDB6j6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANTN8QSDB6j6",
        "outputId": "6bdbd571-e9f2-4e60-dead-7703bf567c7d"
      },
      "source": [
        "sentence = 'Dubinska analiza podataka'\n",
        "\n",
        "processor = nac.OcrAug()\n",
        "ocr = processor.augment(sentence)\n",
        "\n",
        "processor = nac.KeyboardAug()\n",
        "keyboard = processor.augment(sentence)\n",
        "\n",
        "processor = nac.RandomCharAug(action = 'insert')\n",
        "insert = processor.augment(sentence)\n",
        "\n",
        "processor = nac.RandomCharAug(action = 'substitute')\n",
        "substitute = processor.augment(sentence)\n",
        "\n",
        "processor = nac.RandomCharAug(action = 'swap')\n",
        "swap = processor.augment(sentence)\n",
        "\n",
        "processor = nac.RandomCharAug(action = 'delete')\n",
        "delete = processor.augment(sentence)\n",
        "\n",
        "print(*['Orginal tekst -', sentence])\n",
        "print(*['Augmentacija ocr -', ocr])\n",
        "print(*['Augmentacija keyboard -', keyboard])\n",
        "print(*['Augmentacija insert -', insert])\n",
        "print(*['Augmentacija substitute -', substitute])\n",
        "print(*['Augmentacija swap -', swap])\n",
        "print(*['Augmentacija delete -', delete])\n"
      ],
      "id": "ANTN8QSDB6j6",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Orginal tekst - Dubinska analiza podataka\n",
            "Augmentacija ocr - Dubinska analiza p0datara\n",
            "Augmentacija keyboard - Dubinska ana<ixa podataka\n",
            "Augmentacija insert - Dubinska danalUiza podataka\n",
            "Augmentacija substitute - Dubinskz analiza podataka\n",
            "Augmentacija swap - Dunbiska analiza podataka\n",
            "Augmentacija delete - Dubinska anlza podataka\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8PAzE8NB6j7"
      },
      "source": [
        "**Zadatak:**\n",
        "> Izračunati udaljenost rezultnih stringova od originalnog stringa. Ispisati rezultate i analizirati koja metoda je dala najveću različitost.\n",
        ">\n",
        ">> **Uputstvo:**\n",
        ">> Minimalna udaljenost je 0%, a maksimalna 100% i računa se prema formuli: (broj karaktera koji su na korespondentnom mjestu u stringu različiti) / (ukupan broj karaktera) * 100.\n",
        ">>\n",
        ">> Korespondentno mjesto označava istu poziciju karaktera u stringu. Npr. udaljenost između riječi 'dubina' i 'd0bina' je 1, jer se samo karakteri na poziciji 1 ('u' i '0') razlikuju."
      ],
      "id": "U8PAzE8NB6j7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYQrBgK9B6j7",
        "outputId": "185ad69d-45e6-43ee-ddcf-84bfb30b316f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "distances = np.array([0, 0, 0, 0, 0, 0])\n",
        "\n",
        "sentence_length = len(sentence)\n",
        "\n",
        "for i in range(0, sentence_length):\n",
        "    if i >= len(ocr) or sentence[i] != ocr[i]:\n",
        "        distances[0] += 1\n",
        "    if i >= len(keyboard) or sentence[i] != keyboard[i]:\n",
        "        distances[1] += 1\n",
        "    if i >= len(insert) or sentence[i] != insert[i]:\n",
        "        distances[2] += 1\n",
        "    if i >= len(substitute) or sentence[i] != substitute[i]:\n",
        "        distances[3] += 1\n",
        "    if i >= len(swap) or sentence[i] != swap[i]:\n",
        "        distances[4] += 1\n",
        "    if i >= len(delete) or sentence[i] != delete[i]:\n",
        "        distances[5] += 1\n",
        "        \n",
        "        \n",
        "distances = distances / sentence_length * 100\n",
        "\n",
        "print('Udaljenosti:')\n",
        "\n",
        "for i in distances:\n",
        "    print(*[i, '%.'])"
      ],
      "id": "wYQrBgK9B6j7",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Udaljenosti:\n",
            "8.0 %.\n",
            "8.0 %.\n",
            "56.00000000000001 %.\n",
            "4.0 %.\n",
            "12.0 %.\n",
            "48.0 %.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUFRvIi0B6j8"
      },
      "source": [
        "- Najvecu razlicitost je dala `insert` metoda, mada u zavisnosti slucaja moze biti i `delete` metoda, jer ovisi se od indexa pozicije zamjene odnosno brisanja karaktera."
      ],
      "id": "FUFRvIi0B6j8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXT8QxsqB6j8"
      },
      "source": [
        "**Zadatak:**\n",
        "\n",
        "> Tri puta generisati po tri nasumične zamjene na nivou slova po izboru. Analizirati njihovu prosječnu udaljenost od originalnog stringa - da li je približno jednaka?\n",
        ">\n",
        ">> **Uputstvo:**\n",
        ">>\n",
        ">> Za generisanje više zamjena odjednom, pri pozivu funkcije <code> augment </code> dodaje se parametar <code> n = x </code>, pri čemu je <code> x </code> broj stringova koji se žele generisati. Rezultni stringovi su sada u formi liste.\n",
        ">>\n",
        ">> Prosječnu udaljenost za jednu listu izračunati po formuli: (suma udaljenosti svih stringova iz liste) / (broj stringova u listi)."
      ],
      "id": "iXT8QxsqB6j8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7Y_euLmB6j9",
        "outputId": "3dac377c-f56a-419c-dba3-809b4f8f977d"
      },
      "source": [
        "loop_time = 3\n",
        "\n",
        "for loop in range(0, loop_time):\n",
        "    number_of_swaps = 3\n",
        "    \n",
        "    processor = nac.RandomCharAug(action = 'swap')\n",
        "    swaps = processor.augment(sentence, n = number_of_swaps)\n",
        "    \n",
        "    distances_single_loop = np.array([0,0,0])\n",
        "    \n",
        "    for i in range(0, number_of_swaps):\n",
        "        swap = swaps[i]\n",
        "        len_swap = len(swap)\n",
        "        \n",
        "        for j in range(0, sentence_length):\n",
        "            if j >= len_swap or sentence[j] != swap[j]:\n",
        "                distances_single_loop[i] += 1\n",
        "    \n",
        "    distances_single_loop = distances_single_loop / sentence_length * 100\n",
        "    print(*['Average udaljenost pokusaja', loop + 1, '-', sum(distances_single_loop) / 3, '%.'])"
      ],
      "id": "U7Y_euLmB6j9",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average udaljenost pokusaja 1 - 16.0 %.\n",
            "Average udaljenost pokusaja 2 - 13.333333333333334 %.\n",
            "Average udaljenost pokusaja 3 - 16.0 %.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfEDGN6rB6j9"
      },
      "source": [
        "- Prosjecna udaljenost od orginalnog stringa je priblizno jednaka."
      ],
      "id": "vfEDGN6rB6j9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUz816rMB6j9"
      },
      "source": [
        "Za sintetičko kreiranje podataka koristi se i biblioteka <code> snorkel </code>, koju je također potrebno instalirati preko konzole (<code> pip install snorkel </code>). Voditi računa da je instalacija ove biblioteke kompleksniji postupak (zahtijeva instaliran modul Cython i Microsoft Visual C++ 14.0). Sve informacije o korištenju biblioteke mogu se naći na [sljedećem linku](https://buildmedia.readthedocs.org/media/pdf/snorkel/latest/snorkel.pdf).\n",
        "\n",
        "*Snorkel* za augmentaciju koristi dva modula:\n",
        "\n",
        "1. <code> ApplyOnePolicy </code>, objekat koji definiše postavke za sintetičko stvaranje riječi.\n",
        "\n",
        "2. <code> TFApplier </code>, objekat koji vrši sintetičko stvaranje. Ovaj objekat prima dva parametra: listu funkcija koje se žele primijeniti na objekat i prethodno kreiran objekat postavki augmentacije podataka.\n",
        "\n",
        "U tu svrhu potrebno je definisati transformacijsku funkciju (TF) koja će se primijeniti na podatke. U kodu ispod definisana je funkcija koja po principu nasumičnosti vrši zamjenu karaktera iz rečenice nekim drugim karakterom.\n",
        "\n",
        "Nakon definisanja modela za augmentaciju podataka, nad modelom je moguće primijeniti funkciju <code> apply </code>, koja kao parametar prima listu podataka nad kojima se želi primijeniti, a vraća istu listu sa novim redom transformisanih podataka."
      ],
      "id": "YUz816rMB6j9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y96noC3UB6j-"
      },
      "source": [
        "import random\n",
        "import string\n",
        "import numpy as np\n",
        "from snorkel.augmentation import ApplyOnePolicy, TFApplier\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from snorkel.augmentation import transformation_function\n",
        "\n",
        "def replace_token(doc, idx, replacement):\n",
        "    doc = doc[0 : idx] + replacement + doc[idx + 1 :]\n",
        "    return doc\n",
        "\n",
        "@transformation_function()\n",
        "def replace_character_in_word(x):\n",
        "    for i in range(0, (int)(len(x) / 10)):\n",
        "        index = random.randint(0, len(x) - 1)\n",
        "        character = random.choice(string.ascii_lowercase)\n",
        "        x = replace_token(x, index, character)\n",
        "    return x"
      ],
      "id": "y96noC3UB6j-",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y62d3e8B6j-"
      },
      "source": [
        "**Zadatak:**\n",
        "\n",
        "> Definisati model za augmentaciju i izvršiti prethodno definisanu funkciju augmentacije nad rečenicom \"Natural Language Processing Is Amazing\".\n",
        ">\n",
        ">> **Uputstvo:**\n",
        ">>\n",
        ">> Prvo je potrebno definisati postavke, a zatim model augmentacije. U kodu iznad izvršen je import neophodnih klasa objekata.\n",
        ">>\n",
        ">> Model kao prvi parametar prima listu koja treba sadržati transformacijsku funkciju."
      ],
      "id": "7Y62d3e8B6j-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR3LNb50B6j-",
        "outputId": "5808e06e-8032-4590-dfab-89f1f8a9bbf6"
      },
      "source": [
        "aug_sentence = ['Natural Language Processing Is Amazing']\n",
        "\n",
        "policy = ApplyOnePolicy()\n",
        "applier = TFApplier([replace_character_in_word], policy)\n",
        "\n",
        "after_aug_sentence = applier.apply(aug_sentence)\n",
        "\n",
        "print(*['Recenica prije augmentacije:', aug_sentence[0]])\n",
        "print(*['Recenica nakon augmentacije:', after_aug_sentence[1]])"
      ],
      "id": "WR3LNb50B6j-",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 942.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Recenica prije augmentacije: Natural Language Processing Is Amazing\n",
            "Recenica nakon augmentacije: Namural Langubge Processing Is Amaling\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cptLnNQMB6j_"
      },
      "source": [
        "**Zadatak:**\n",
        "\n",
        "> Samostalno definisati funkciju koja izvršava zamjenu karaktera u riječi na sličan način kao funkcije iz prvog dijela zadatka (po želji). Izvršiti augmentaciju podataka i usporediti dobivene rezultate."
      ],
      "id": "cptLnNQMB6j_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67AY1vXWB6j_",
        "outputId": "641d3545-6d90-441b-ec62-6d59b8e99604"
      },
      "source": [
        "@transformation_function()\n",
        "def swap_random_three_values(x):\n",
        "    for i in range(0, (int)(len(x) / 15)):\n",
        "        index = random.randint(0, len(x) - 1)\n",
        "        second_index = random.randint(0, len(x) - 1)\n",
        "        third_index = random.randint(0, len(x) - 1)\n",
        "\n",
        "        first_value = x[index]\n",
        "        second_value = x[second_index]\n",
        "        third_value = x[third_index]\n",
        "        \n",
        "        x = x[0 : index] + third_value + x[index + 1 :]\n",
        "        x = x[0 : second_index] + first_value + x[second_index + 1 :]\n",
        "        x = x[0 : third_index] + second_value + x[third_index + 1 :]\n",
        "\n",
        "    return x\n",
        "\n",
        "aug_sentence = ['Natural Language Processing Is Amazing']\n",
        "\n",
        "policy = ApplyOnePolicy()\n",
        "applier = TFApplier([swap_random_three_values], policy)\n",
        "\n",
        "after_aug_sentence = applier.apply(aug_sentence)\n",
        "\n",
        "print(*['Recenica prije augmentacije:', aug_sentence[0]])\n",
        "print(*['Recenica nakon augmentacije:', after_aug_sentence[1]])"
      ],
      "id": "67AY1vXWB6j_",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2945.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Recenica prije augmentacije: Natural Language Processing Is Amazing\n",
            "Recenica nakon augmentacije: Natug lsLanguage Proceasinr Is Amazing\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj8hOd0IB6kA"
      },
      "source": [
        "- `swap_random_three_values` uzima tri slucajna karaktera i mijenja ih ciklicno u stringu. Vidimo da duzina ostaje ista, samo se mijenjaju 3 karaktera."
      ],
      "id": "fj8hOd0IB6kA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_IND5KnB6kA"
      },
      "source": [
        "---\n",
        "\n",
        "## Zadatak 2. - Zamjena stringa na nivou riječi\n",
        "\n",
        "Zamjena na nivou riječi vrši se koristeći različite objekte iz biblioteke <code> nlpaug.augmenter.word </code>. U nastavku će se koristiti sljedeći objekti:\n",
        "\n",
        "1. <code> naw.SpellingAug() </code>, koji vrši zamjenu riječi koristeći greške u spelovanju;\n",
        "\n",
        "2. <code> naw.ContextualWordEmbsAug() </code>, koji vrši zamjenu riječi na osnovu kontekstualne sličnosti, pritom koristeći jedan od šest dostupnih algoritama (npr. <code> bert-base-uncased </code>, <code> distilbert-base-uncased </code> ili <code> roberta-base </code>). Za korištenje objekta ovog tipa potrebno je instalirati dodatnu biblioteku: <code> pip install transformers </code>;\n",
        "\n",
        "3. <code> naw.AntonymAug() </code>, koji vrši zamjenu riječi na osnovu antonima;\n",
        "\n",
        "4. <code> naw.SynonymAug() </code>, koji vrši zamjenu riječi na osnovu sinonima registrovanih u nekoj od dostupnih baza riječi (<code> 'wordnet' </code> ili <code> 'ppdb' </code>);\n",
        "\n",
        "5. <code> naw.RandomWordAug() </code>, koji vrši zamjenu mjesta postojećih riječi koristeći nasumičnu preraspodjelu.\n",
        "\n",
        "Nad kreiranim objektom za zamjenu na nivou riječi može se primijeniti funkcija <code> augment </code>, na isti način kao i u prethodnom zadatku."
      ],
      "id": "-_IND5KnB6kA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXH77hlgB6kA"
      },
      "source": [
        "**Zadatak:**\n",
        "    \n",
        "> Definisati string 'DAP is one of the subjects of the final semester at the Faculty of Electrical Engineering.', a zatim nad njim izvršiti zamjenu na nivou riječi koristeći sve prethodno opisane objekte. Prikazati originalni i sve modificirane stringove.\n",
        ">\n",
        ">> **Uputstvo:**\n",
        ">>\n",
        ">> Sve rezultujuće stringove smjestiti u zasebne varijable, jer će ih biti neophodno koristiti u sljedećem dijelu zadatka. Paziti da se ne pobriše vrijednost originalnog stringa (iz istog razloga).\n",
        ">>\n",
        ">> naw.ContextualWordEmbsAug() prima jedan parametar: <code> model_path </code>, koji se postavlja na jedan od postojećih algoritama.\n",
        ">>\n",
        ">> naw.SynonymAug() prima jedan parametar: <code> model_path </code>, koji se postavlja na jednu od dostupnih baza podataka.\n",
        ">>\n",
        ">> naw.RandomWordAug() prima jedan parametar: <code> action </code>, koji se postavlja na <code> 'swap' </code>."
      ],
      "id": "aXH77hlgB6kA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfl3_kD1B6kA",
        "outputId": "663f317d-dbe1-4cd5-a619-6f81dd8d4c72"
      },
      "source": [
        "import nlpaug.augmenter.word as naw\n",
        "\n",
        "sentence = \"DAP is one of the subjects of the final semester at the Faculty of Electrical Engineering.\"\n",
        "\n",
        "processor = naw.SpellingAug()\n",
        "spelling = processor.augment(sentence)\n",
        "\n",
        "processor = naw.ContextualWordEmbsAug(model_path = \"bert-base-uncased\")\n",
        "context = processor.augment(sentence)\n",
        "\n",
        "processor = naw.AntonymAug()\n",
        "antonyms = processor.augment(sentence)\n",
        "\n",
        "processor = naw.SynonymAug(aug_src='wordnet')\n",
        "synonims = processor.augment(sentence)\n",
        "\n",
        "processor = naw.RandomWordAug(action = 'swap')\n",
        "random_swap = processor.augment(sentence)\n",
        "\n",
        "print(*['Orginal tekst -', sentence])\n",
        "print(*['Augmentacija spelling -', spelling])\n",
        "print(*['Augmentacija context -', context])\n",
        "print(*['Augmentacija antonimi -', antonyms])\n",
        "print(*['Augmentacija synonims -', synonims])\n",
        "print(*['Augmentacija random swap -', random_swap])\n"
      ],
      "id": "Gfl3_kD1B6kA",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Orginal tekst - DAP is one of the subjects of the final semester at the Faculty of Electrical Engineering.\n",
            "Augmentacija spelling - DAP is 1one of tehere sobjects of the finel semester at the Facolty of Electrical Engineering.\n",
            "Augmentacija context - dap selection one by the subjects of the final program at the faculty at environmental engineering.\n",
            "Augmentacija antonimi - DAP differ one of the subjects of the final semester at the Faculty of Electrical Engineering.\n",
            "Augmentacija synonims - DAP constitute unitary of the field of study of the final semester at the Faculty of Electrical Engineering.\n",
            "Augmentacija random swap - is DAP one of the subjects of the semester final the Faculty at Electrical of Engineering.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWQ0CdmlB6kB"
      },
      "source": [
        "**Zadatak:**\n",
        "> Izračunati udaljenost rezultnih stringova od originalnog stringa. Ispisati rezultate i analizirati koja metoda je dala najveću različitost.\n",
        ">\n",
        ">> **Uputstvo:**\n",
        ">> Minimalna udaljenost je 0%, a maksimalna 100% i računa se prema formuli: (broj riječi koje su na korespondentnom mjestu u stringu različite) / (ukupan broj riječi) * 100.\n",
        ">>\n",
        ">> Korespondentno mjesto označava isti broj riječi u stringu. Npr. udaljenost između rečenica 'dubina nije' i 'dubina je' je 1, jer se samo riječi na poziciji 1 ('nije' i 'je') razlikuju.\n",
        ">>\n",
        ">> Za razdvajanje stringa u listu riječi može se koristiti funkcija <code> split </code> sa razmakom kao delimiterom."
      ],
      "id": "AWQ0CdmlB6kB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgoTOJ5lB6kB",
        "outputId": "f922bad8-1fa5-48f9-f825-a4a824f98e91"
      },
      "source": [
        "distances = np.array([0, 0, 0, 0, 0])\n",
        "\n",
        "sentence_length = len(sentence)\n",
        "sentence_w = sentence.split(\" \")\n",
        "\n",
        "spelling_w = spelling.split(\" \")\n",
        "context_w = context.split(\" \")\n",
        "antonyms_w = antonyms.split(\" \")\n",
        "synonims_w = synonims.split(\" \")\n",
        "random_w = random_swap.split(\" \")\n",
        "\n",
        "number_words = len(sentence_w)\n",
        "\n",
        "for i in range(0, number_words):\n",
        "    if sentence_w[i] != spelling_w[i]:\n",
        "        distances[0] += 1\n",
        "    if sentence_w[i] != context_w[i]:\n",
        "        distances[1] += 1\n",
        "    if sentence_w[i] != antonyms_w[i]:\n",
        "        distances[2] += 1\n",
        "    if sentence_w[i] != synonims_w[i]:\n",
        "        distances[3] += 1\n",
        "    if sentence_w[i] != random_w[i]:\n",
        "        distances[4] += 1\n",
        "\n",
        "        \n",
        "distances = distances / number_words * 100\n",
        "\n",
        "print('Udaljenosti:')\n",
        "\n",
        "for i in distances:\n",
        "    print(*[i, '%.'])"
      ],
      "id": "DgoTOJ5lB6kB",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Udaljenosti:\n",
            "31.25 %.\n",
            "50.0 %.\n",
            "6.25 %.\n",
            "75.0 %.\n",
            "56.25 %.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY7CK72tGmfj"
      },
      "source": [
        "- Najvecu razlicitost u vecini slucajeva je dala `SynonymAug` metoda"
      ],
      "id": "uY7CK72tGmfj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAABbb20B6kB"
      },
      "source": [
        "I za zamjenu na nivou riječi koristi se <code> snorkel </code> biblioteka, na isti način kao i u prethodnom zadatku. U tu svrhu koriste se isti objekti (model za augmentaciju i postavke), ali je struktura transformacijskih funkcija drukčija.\n",
        "    \n",
        "U nastavku je prikazan kod kojim se definiše transformacijska funkcija (TF) za zamjenu riječi u rečenici sa sinonimom iz baze podataka *WordNet*."
      ],
      "id": "zAABbb20B6kB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GurlDZj_B6kC"
      },
      "source": [
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from snorkel.augmentation import transformation_function\n",
        "from snorkel.augmentation import ApplyOnePolicy, TFApplier\n",
        "\n",
        "def get_synonyms(word):\n",
        "    lemmas = set().union(*[s.lemmas() for s in wn.synsets(word)])\n",
        "    return list(set(l.name().lower().replace(\"_\", \" \") for l in lemmas) - {word})\n",
        "\n",
        "\n",
        "@transformation_function()\n",
        "def tf_replace_word_with_synonym(x):\n",
        "    words = x.lower().split()\n",
        "    idx = random.choice(range(len(words)))\n",
        "    synonyms = get_synonyms(words[idx])\n",
        "    if len(synonyms) > 0:\n",
        "        x = \" \".join(words[:idx] + [synonyms[0]] + words[idx + 1 :])\n",
        "        return x"
      ],
      "id": "GurlDZj_B6kC",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6BMLb82B6kC"
      },
      "source": [
        "**Zadatak:**\n",
        "\n",
        "> Zamijeniti riječi u rečenici \"Natural Language Processing Is Amazing\" sa sinonimima. Generisati pet takvih rečenica.\n",
        ">\n",
        ">> **Uputstvo:**\n",
        ">>\n",
        ">> Kreirati objekte na isti način kao u prethodnom zadatku, s tim što je pri kreiranju objekta postavki <code> ApplyOnePolicy </code> potrebno dodati parametar <code> n_per_original </code> kojim se definiše broj izlaznih rečenica."
      ],
      "id": "e6BMLb82B6kC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drITl_wIB6kC",
        "outputId": "a50f58e3-1126-456a-8c79-489bac33d674"
      },
      "source": [
        "aug_sentence = ['Natural Language Processing Is Amazing']\n",
        "\n",
        "policy = ApplyOnePolicy(n_per_original = 5, keep_original = True)\n",
        "applier = TFApplier([tf_replace_word_with_synonym], policy)\n",
        "\n",
        "after_aug_sentences = applier.apply(aug_sentence)\n",
        "\n",
        "print(*['Recenica prije augmentacije:', aug_sentence[0]])\n",
        "print('Recenice nakon augmentacije:')\n",
        "\n",
        "for i in range(1, len(after_aug_sentences)):\n",
        "  print(after_aug_sentence[i])"
      ],
      "id": "drITl_wIB6kC",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 119.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Recenica prije augmentacije: Natural Language Processing Is Amazing\n",
            "Recenice nakon augmentacije:\n",
            "natural language processing is awful\n",
            "natural voice communication processing is amazing\n",
            "innate language processing is amazing\n",
            "natural voice communication processing is amazing\n",
            "natural language processing exist amazing\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCeVYIwLB6kC"
      },
      "source": [
        "---\n",
        "\n",
        "## Zadatak 3. - Zamjena stringa na nivou rečenice\n",
        "\n",
        "Zamjena na nivou rečenice vrši se koristeći različite objekte iz biblioteke <code> nlpaug.augmenter.sentence </code>. U nastavku će se koristiti sljedeći objekat:\n",
        "\n",
        "<code> nas.ContextualWordEmbsForSentenceAug() </code>, koji vrši dodavanje nove rečenice na osnovu kontekstualnog značenja izvornog stringa. Ovaj objekat kao parametar prima <code> model_path </code>, koji je moguće postaviti na jednu od tri vrijednosti: <code> xlnet-base-cased </code>, <code> gpt2 </code> ili <code> distilgpt2 </code>.\n",
        "\n",
        "Nad kreiranim objektom za zamjenu na nivou rečenice može se primijeniti funkcija <code> augment </code>, na isti način kao i u prethodnom zadatku."
      ],
      "id": "gCeVYIwLB6kC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i3HUPKuB6kC"
      },
      "source": [
        "**Zadatak:**\n",
        "\n",
        "> Definisati rečenicu 'Studying hard pays off because if you study hard you will gain the best grade.' a zatim nad njom kreirati po tri nove rečenice koristeći sva tri dostupna algoritma za generisanje novih rečenica na osnovu konteksta.\n",
        ">\n",
        ">> **Uputstvo:**\n",
        ">>\n",
        ">> Pri prvom pokretanju za svaki novi algoritam potrebno je preuzeti neophodne *file*-ove, što može potrajati nekoliko minuta.\n",
        ">>\n",
        ">> Za definisanje broja rečenica koje se žele generisati može se koristiti parametar <code> n </code> u funkciji <code> augment </code>, na isti način kao i u prethodnim zadacima."
      ],
      "id": "2i3HUPKuB6kC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZkBvGc8B6kD",
        "outputId": "37c894a4-272d-4b27-8268-a713c504921d"
      },
      "source": [
        "sentence = \"Studying hard pays off because if you study hard you will gain the best grade\"\n",
        "\n",
        "processor = nas.ContextualWordEmbsForSentenceAug(model_path = 'xlnet-base-cased')\n",
        "xlnet = processor.augment(sentence, n = 3)\n",
        "\n",
        "processor = nas.ContextualWordEmbsForSentenceAug(model_path = 'gpt2')\n",
        "gpt2 = processor.augment(sentence, n = 3)\n",
        "\n",
        "processor = nas.ContextualWordEmbsForSentenceAug(model_path = 'distilgpt2')\n",
        "distilgpt2 = processor.augment(sentence, n = 3)\n",
        "\n",
        "print(*['Original:', sentence])\n",
        "\n",
        "print('xlnet algoritam:')\n",
        "for i in xlnet:\n",
        "  print(i)\n",
        "\n",
        "print('gpt2 algoritam:')\n",
        "for i in gpt2:\n",
        "  print(i)\n",
        "\n",
        "print('distilgpt2 algoritam:')\n",
        "for i in distilgpt2:\n",
        "  print(i)\n",
        "\n"
      ],
      "id": "fZkBvGc8B6kD",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: Studying hard pays off because if you study hard you will gain the best grade\n",
            "xlnet algoritam:\n",
            "Studying hard pays off because if you study hard you will gain the best grade at a school this subject offers!\n",
            "Studying hard pays off because if you study hard you will gain the best grade when gaining computer classes like C-PS classes For online classes.\n",
            "Studying hard pays off because if you study hard you will gain the best grade at all events of your life during that course!\n",
            "gpt2 algoritam:\n",
            "Studying hard pays off because if you study hard you will gain the best grade , i ion ( el in es : ies ( ) at / ic , t , as s , and ah 3 , s n 1 i on .\n",
            "Studying hard pays off because if you study hard you will gain the best grade ia es d for ar ing s I es s ing at - in - , at it and was an for d ing , er - j The .\n",
            "Studying hard pays off because if you study hard you will gain the best grade on I r io r o g ar _ er ar is es ig I ol i al - _ ) ik io A o i with , in es\n",
            "distilgpt2 algoritam:\n",
            "Studying hard pays off because if you study hard you will gain the best grade H , As It You i to .\n",
            "Studying hard pays off because if you study hard you will gain the best grade U A A A A S in T K R C and My The W She 2 J V R He the F the As You A S the A\n",
            "Studying hard pays off because if you study hard you will gain the best grade in The The For in the To The In The s We 4 0 and 3 V She \" T S We A The I A � The s 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4SljLMaB6kD"
      },
      "source": [
        "Analizirati prethodno generisane rečenice. Da li neke od njih nisu kontekstualno slične originalnoj rečenici? Da li se može odrediti na osnovu čega (kojeg dijela rečenice) su generisane baš takve rečenice?\n",
        "\n",
        "- Neke od generisanih recenica nisu kontekstualno slicne recenici\n",
        "- Moze, na osnovu random karaktera ili na osnovu jendnostavnosti da se bas ne uklapaju u smisao recenice, ali gledajuci u vidu konteksta, tu se nalaze."
      ],
      "id": "p4SljLMaB6kD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m99to3IyB6kD"
      },
      "source": [
        "**Zadatak:**\n",
        "\n",
        "> Promijeniti postavke parametara u nastojanju da se postignu bolji rezultati.\n",
        ">\n",
        ">> **Uputstvo:**\n",
        ">>\n",
        ">> Koristiti isključivo <code> xlnet-base-cased </code> model. Promijeniti parametar <code> temperature </code> na 0.5 i 0.01. Promijeniti parametar <code> top_k </code> na 10, 200, 500 i 1000."
      ],
      "id": "m99to3IyB6kD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHOVEfhfB6kD",
        "outputId": "451dd088-08a5-4987-8920-e5d192f226c9"
      },
      "source": [
        "sentence = \"Studying hard pays off because if you study hard you will gain the best grade\"\n",
        "\n",
        "temperatures = [0.5, 0.01]\n",
        "top_k = [10, 200, 500, 1000]\n",
        "\n",
        "for temp in temperatures:\n",
        "  for k in top_k:\n",
        "    processor = nas.ContextualWordEmbsForSentenceAug(model_path = 'xlnet-base-cased', temperature = temp, top_k = k)\n",
        "    xlnet = processor.augment(sentence, n = 3)\n",
        "    print(*['Augmentacija nad temperaturom:', temp, 'i k:', k])\n",
        "    for i in xlnet:\n",
        "      print(i)\n"
      ],
      "id": "yHOVEfhfB6kD",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmentacija nad temperaturom: 0.5 i k: 10\n",
            "Studying hard pays off because if you study hard you will gain the best grade in math science or science writing skills in the college of you choice at age 13 through 17 without even knowing your major.\n",
            "Studying hard pays off because if you study hard you will gain the best grade of your college.\n",
            "Studying hard pays off because if you study hard you will gain the best grade in every major in college you ever took in your first 10 years!\n",
            "Augmentacija nad temperaturom: 0.5 i k: 200\n",
            "Studying hard pays off because if you study hard you will gain the best grade possible with the exam of this exam.\n",
            "Studying hard pays off because if you study hard you will gain the best grade for every single single project.\n",
            "Studying hard pays off because if you study hard you will gain the best grade from each subject that is tested to 100% on every final exam and homework every final homework you get through all exam for the first time of the exam every\n",
            "Augmentacija nad temperaturom: 0.5 i k: 500\n",
            "Studying hard pays off because if you study hard you will gain the best grade on all subjects as time moves towards the major of your choice and college enrollment becomes in greater force for young American citizens in subsequent generation or more decades-\n",
            "Studying hard pays off because if you study hard you will gain the best grade in class in a matter of four or eight semester.\n",
            "Studying hard pays off because if you study hard you will gain the best grade .\n",
            "Augmentacija nad temperaturom: 0.5 i k: 1000\n",
            "Studying hard pays off because if you study hard you will gain the best grade in you you are sure you want and already for many a good student it happens.\n",
            "Studying hard pays off because if you study hard you will gain the best grade for everything about your future.\n",
            "Studying hard pays off because if you study hard you will gain the best grade .\n",
            "Augmentacija nad temperaturom: 0.01 i k: 10\n",
            "Studying hard pays off because if you study hard you will gain the best grade in your college and university.\n",
            "Studying hard pays off because if you study hard you will gain the best grade in your college and university.\n",
            "Studying hard pays off because if you study hard you will gain the best grade you can.\n",
            "Augmentacija nad temperaturom: 0.01 i k: 200\n",
            "Studying hard pays off because if you study hard you will gain the best grade you can get for your homework.\n",
            "Studying hard pays off because if you study hard you will gain the best grade you can.\n",
            "Studying hard pays off because if you study hard you will gain the best grade in your school.\n",
            "Augmentacija nad temperaturom: 0.01 i k: 500\n",
            "Studying hard pays off because if you study hard you will gain the best grade you can get.\n",
            "Studying hard pays off because if you study hard you will gain the best grade in your school.\n",
            "Studying hard pays off because if you study hard you will gain the best grade you can get at your college or university.\n",
            "Augmentacija nad temperaturom: 0.01 i k: 1000\n",
            "Studying hard pays off because if you study hard you will gain the best grade in your college.\n",
            "Studying hard pays off because if you study hard you will gain the best grade you can.\n",
            "Studying hard pays off because if you study hard you will gain the best grade you can.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYEqAoz5B6kD"
      },
      "source": [
        "Analizirati prethodno generisane rečenice. Koja kombinacija parametara je dala najbolje, a koja najgore rezultate? Šta se iz toga može zaključiti o važnosti parametara <code> temperature </code> i <code> top_k </code>?"
      ],
      "id": "HYEqAoz5B6kD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGCI0pS4B6kD"
      },
      "source": [
        "- Smanjenje temperature utice na smanjenje random mogucih dobijenih rijeci, i sto manja temperatura vise je logicniji odgovor u skladu pocetne recenice. Najbolji rezultati su dobijeni za `temp=0.01`\n",
        "- Sto veci `top_k` znaci vise tokena koji mogu prouzrokovati drugacije rijeci, najbolji rezultat je dobijen za `top_k=500`."
      ],
      "id": "bGCI0pS4B6kD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOfssLEZB6kD"
      },
      "source": [
        "---\n",
        "\n",
        "## Zadatak 4. - Automatsko generisanje kratkog pregleda\n",
        "\n",
        "Najviši nivo na kojem se može vršiti sintetičko kreiranje tekstualnih podataka je nivo diskursa. U tu svrhu koristi se isti modul kao i u prethodnom zadatku (<code> nlpaug.augmenter.sentence </code>). U nastavku će se koristiti sljedeći objekat:\n",
        "\n",
        "<code> nas.AbstSummAug() </code>, koji kao parametar prima <code> model_path </code> za vrstu algoritma za transformaciju teksta (<code> facebook/bart-large-cnn </code>, <code> t5-small </code>, <code> t5-base </code> ili <code> t5-large </code>).\n",
        "\n",
        "Nad kreiranim objektom za kreiranje kratkog pregleda može se primijeniti funkcija <code> augment </code>, na isti način kao i u prethodnom zadatku."
      ],
      "id": "QOfssLEZB6kD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJLPOQm1B6kE"
      },
      "source": [
        "**Zadatak:**\n",
        "\n",
        "> Kreirati string koji se sastoji od najmanje pet rečenica na engleskom jeziku po vlastitom izboru. Zatim kreirati kratke preglede koristeći prethodno definisane algoritme t5-small i t5-base (preostala dva algoritma su previše vremenski i memorijski zahtjevna). Analizirati koji od kratkih pregleda je najreprezentativniji.\n",
        ">\n",
        ">> **Uputstvo:**\n",
        ">>\n",
        ">> Za definisanje teksta sa više redova u kodu koristiti trostruke navodnike (\"\"\") umjesto jednostrukih (\").\n",
        ">>\n",
        ">> Preuzimanje svih neophodnih *file*-ova za modele može potrajati nekoliko minuta."
      ],
      "id": "CJLPOQm1B6kE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvRjCXEAB6kE",
        "outputId": "23558f0a-1efe-4ce8-bc8f-8497285be18d"
      },
      "source": [
        "five_sentences = \"\"\"\n",
        "If you're visiting this page, you're likely here because you're searching for a random sentence. \n",
        "Sometimes a random word just isn't enough, and that is where the random sentence generator comes into play. \n",
        "By inputting the desired number, you can make a list of as many random sentences as you want or need. \n",
        "Producing random sentences can be helpful in a number of different ways.\n",
        "Feel free to use any of the random sentences for any project that you may be doing.\n",
        "\"\"\"\n",
        "\n",
        "processor = nas.AbstSummAug(model_path = 't5-small')\n",
        "view = processor.augment(five_sentences)\n",
        "\n",
        "print(*['t5-small view:', view])\n",
        "\n",
        "processor = nas.AbstSummAug(model_path = 't5-base')\n",
        "view = processor.augment(five_sentences)\n",
        "\n",
        "print(*['t5-base view:', view])\n",
        "\n"
      ],
      "id": "JvRjCXEAB6kE",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t5-small view: the random sentence generator comes into play. make a list of as many random sentences as you want or need.\n",
            "t5-base view: the random sentence generator can help you create a list of as many random sentences as you want. use the random sentences for any project that you may be doing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOr2uPxiV6SX"
      },
      "source": [
        "- Najreprezentavniji predstavlja `t5-small`, jer je jednostavniji i konkretniji pregled."
      ],
      "id": "OOr2uPxiV6SX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhcFCe_HB6kE"
      },
      "source": [
        "**Zadatak:**\n",
        "\n",
        "> Promijeniti postavke parametara u nastojanju da se postignu bolji rezultati.\n",
        ">\n",
        ">> Koristiti isključivo jedan model koji se odredi kao najtačniji u prethodnom dijelu zadatka.\n",
        ">>\n",
        ">> Pri kreiranju objekta dodati parametar <code> num_beam </code>. Postaviti njegovu vrijednost na 1, 5 i 10."
      ],
      "id": "MhcFCe_HB6kE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhdpLd7oB6kE",
        "outputId": "e811b6ab-839b-45d3-98ec-a1b34c0e13d4"
      },
      "source": [
        "beams = [1, 5, 10]\n",
        "\n",
        "for beam in beams:\n",
        "  processor = nas.AbstSummAug(model_path = 't5-small', num_beam = beam)\n",
        "  view = processor.augment(five_sentences)\n",
        "\n",
        "  print(*['View t5-small, num_beam =', beam, '-', view])"
      ],
      "id": "YhdpLd7oB6kE",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "View t5-small, num_beam = 1 - random sentences can be useful in a number of different ways. create random sentences by inputting the desired number.\n",
            "View t5-small, num_beam = 5 - the random sentence generator comes into play. make a list of as many random sentences as you want or need.\n",
            "View t5-small, num_beam = 10 - the random sentence generator comes into play. make a list of as many random sentences as you want or need.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NOJEfaDB6kE"
      },
      "source": [
        "Analizirati prethodno generisane kratke preglede. Koja kombinacija parametara je dala najbolje, a koja najgore rezultate? Šta se iz toga može zaključiti o važnosti parametara <code> num_beam </code> ?"
      ],
      "id": "4NOJEfaDB6kE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWYCuF4wB6kE"
      },
      "source": [
        "- Veci `num_bean` rezultira da ce se uzimati vise rijeci i za svaku rijec pokusati generisati vise recenica. Veci `num_bean` znaci vise koristenje resura ali razarada vise varijacija za najbolje rijeci po vjerovatnoci odnosno formiranje recenice po najvjerovatnijim konteksnim rijecima. Najbolji rezultat daje `num_bean=5` jer `num_bean=10` daje isti rezultat, ali koristi manje resursa.\n",
        "\n"
      ],
      "id": "GWYCuF4wB6kE"
    }
  ]
}